{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFXqphfneRM3tkLCvcU854",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samer-glitch/Trustworthy-AI-Data-Pipeline-Framework/blob/main/7_Data_Logging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx7uAaieViEw"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "# Create a logger instance\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Check and clear existing handlers to avoid duplicated logs or formatting issues\n",
        "if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "\n",
        "# Create a file handler for logging\n",
        "log_file_path = '/content/data_pipeline_report.txt'\n",
        "file_handler = logging.FileHandler(log_file_path, mode='w')\n",
        "file_handler.setLevel(logging.INFO)\n",
        "\n",
        "# Create a custom formatter for output\n",
        "formatter = logging.Formatter(\n",
        "    '%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "# Add the handler to the logger\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "# Start of the data logging pipeline process\n",
        "logger.info('Data Preprocessing Pipeline Log')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "df = pd.read_csv(url)\n",
        "logger.info('Dataset Loaded')\n",
        "logger.info('Dataset loaded from: %s' % url)\n",
        "logger.info('Initial dataset shape: %s' % str(df.shape))\n",
        "\n",
        "# Snapshot of the first few rows of the dataset\n",
        "logger.info('Initial Data Snapshot')\n",
        "logger.info('\\n%s' % df.head(4).to_string(index=False))"
      ],
      "metadata": {
        "id": "p-sRy9AeYOki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values in 'Age' column\n",
        "missing_values_before = df['Age'].isnull().sum()\n",
        "mean_age_value = df['Age'].mean()\n",
        "logger.info('Handling Missing Values')\n",
        "logger.info('Initial missing values in \"Age\" column: %d' % missing_values_before)\n",
        "df['Age'] = df['Age'].fillna(mean_age_value)\n",
        "logger.info('Missing values in \"Age\" column filled with mean value: %.2f' % mean_age_value)\n",
        "missing_values_after = df['Age'].isnull().sum()\n",
        "logger.info('Remaining missing values in \"Age\" column after imputation: %d' % missing_values_after)"
      ],
      "metadata": {
        "id": "T6ixtQucYUgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing duplicates\n",
        "initial_row_count = df.shape[0]\n",
        "df = df.drop_duplicates()\n",
        "final_row_count = df.shape[0]\n",
        "duplicates_removed = initial_row_count - final_row_count\n",
        "logger.info('Removing Duplicates')\n",
        "logger.info('Duplicates removed: %d. Rows before: %d, Rows after: %d' % (duplicates_removed, initial_row_count, final_row_count))"
      ],
      "metadata": {
        "id": "Lq3g1MuYYbR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# One-Hot Encoding the 'Sex', 'Embarked', and 'Cabin' columns\n",
        "logger.info('One-Hot Encoding Categorical Columns')\n",
        "categorical_columns = ['Sex', 'Embarked', 'Cabin']\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform='pandas')\n",
        "\n",
        "# Fit and transform\n",
        "encoded_df = encoder.fit_transform(df[categorical_columns])\n",
        "\n",
        "# Convert float values to integers for better representation\n",
        "encoded_df = encoded_df.astype(int)\n",
        "\n",
        "# Log the columns created by one-hot encoding\n",
        "logger.info('Columns after one-hot encoding: %s' % encoded_df.columns.tolist())\n",
        "\n",
        "# Concatenate encoded dataframe back to the main dataframe\n",
        "df = pd.concat([df.drop(columns=categorical_columns), encoded_df], axis=1)\n",
        "\n",
        "# Snapshot of the first few rows of the dataset after encoding\n",
        "logger.info('Dataset after one-hot encoding:\\n%s' % df.head(4).to_string(index=False))"
      ],
      "metadata": {
        "id": "uMmn_Ta8YgCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "numerical_columns = ['Age', 'Fare']\n",
        "logger.info('Scaling Numerical Features')\n",
        "logger.info('Summary statistics before scaling:')\n",
        "logger.info('\\n%s' % df[numerical_columns].describe().to_string())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "logger.info('Numerical features scaled using StandardScaler.')\n",
        "logger.info('Summary statistics after scaling:')\n",
        "logger.info('\\n%s' % df[numerical_columns].describe().to_string())"
      ],
      "metadata": {
        "id": "WZHX1J-qYlQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Drop non-numerical columns to handle class imbalance properly\n",
        "non_numerical_columns = ['Name', 'Ticket']\n",
        "df = df.drop(columns=non_numerical_columns)\n",
        "\n",
        "# Define features and target\n",
        "logger.info('Handling Class Imbalance with SMOTE')\n",
        "target = 'Survived'\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "# Log class imbalance before SMOTE\n",
        "logger.info('Original target class distribution:\\n%s' % y.value_counts().to_string())\n",
        "\n",
        "# Applying SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Log class imbalance after SMOTE\n",
        "logger.info('Resampled target class distribution:\\n%s' % pd.Series(y_resampled).value_counts().to_string())"
      ],
      "metadata": {
        "id": "adJXd1heYtVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 10]\n",
        "}\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "logger.info('Hyperparameter Tuning and Cross-Validation')\n",
        "logger.info('Performed hyperparameter tuning using GridSearchCV.')\n",
        "logger.info('Best parameters found: %s' % grid_search.best_params_)\n",
        "logger.info('Best cross-validation score: %.2f%%' % (grid_search.best_score_ * 100))"
      ],
      "metadata": {
        "id": "EF5zASGdZvf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure log file is written to disk\n",
        "for handler in logger.handlers:\n",
        "    handler.flush()\n",
        "\n",
        "# Verify if the log file is created using Python\n",
        "if os.path.exists(log_file_path):\n",
        "    # Read and print the content of the log file\n",
        "    with open(log_file_path, 'r') as file:\n",
        "        log_content = file.read()\n",
        "    print(\"----- Log File Content -----\")\n",
        "    print(log_content)\n",
        "else:\n",
        "    print(\"Log file not found\")\n",
        "\n",
        "# Attempt to download the log file if it exists\n",
        "from google.colab import files\n",
        "if os.path.exists(log_file_path):\n",
        "    files.download(log_file_path)\n",
        "else:\n",
        "    print(\"Cannot download the log file as it wasn't found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tWLVwHJnZ4QY",
        "outputId": "cbf15764-6952-44b8-9b63-7e77c0426fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Log File Content -----\n",
            "2024-10-30 07:42:38 - INFO - Data Preprocessing Pipeline Log\n",
            "2024-10-30 07:43:17 - INFO - Dataset Loaded\n",
            "2024-10-30 07:43:17 - INFO - Dataset loaded from: https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
            "2024-10-30 07:43:17 - INFO - Initial dataset shape: (891, 12)\n",
            "2024-10-30 07:43:17 - INFO - Initial Data Snapshot\n",
            "2024-10-30 07:43:17 - INFO - \n",
            " PassengerId  Survived  Pclass                                                Name    Sex  Age  SibSp  Parch           Ticket    Fare Cabin Embarked\n",
            "           1         0       3                             Braund, Mr. Owen Harris   male 22.0      1      0        A/5 21171  7.2500   NaN        S\n",
            "           2         1       1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0      1      0         PC 17599 71.2833   C85        C\n",
            "           3         1       3                              Heikkinen, Miss. Laina female 26.0      0      0 STON/O2. 3101282  7.9250   NaN        S\n",
            "           4         1       1        Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0      1      0           113803 53.1000  C123        S\n",
            "2024-10-30 07:43:40 - INFO - Handling Missing Values\n",
            "2024-10-30 07:43:40 - INFO - Initial missing values in \"Age\" column: 177\n",
            "2024-10-30 07:43:40 - INFO - Missing values in \"Age\" column filled with mean value: 29.70\n",
            "2024-10-30 07:43:40 - INFO - Remaining missing values in \"Age\" column after imputation: 0\n",
            "2024-10-30 07:44:09 - INFO - Removing Duplicates\n",
            "2024-10-30 07:44:09 - INFO - Duplicates removed: 0. Rows before: 891, Rows after: 891\n",
            "2024-10-30 07:44:28 - INFO - One-Hot Encoding Categorical Columns\n",
            "2024-10-30 07:44:28 - INFO - Columns after one-hot encoding: ['Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Embarked_nan', 'Cabin_A10', 'Cabin_A14', 'Cabin_A16', 'Cabin_A19', 'Cabin_A20', 'Cabin_A23', 'Cabin_A24', 'Cabin_A26', 'Cabin_A31', 'Cabin_A32', 'Cabin_A34', 'Cabin_A36', 'Cabin_A5', 'Cabin_A6', 'Cabin_A7', 'Cabin_B101', 'Cabin_B102', 'Cabin_B18', 'Cabin_B19', 'Cabin_B20', 'Cabin_B22', 'Cabin_B28', 'Cabin_B3', 'Cabin_B30', 'Cabin_B35', 'Cabin_B37', 'Cabin_B38', 'Cabin_B39', 'Cabin_B4', 'Cabin_B41', 'Cabin_B42', 'Cabin_B49', 'Cabin_B5', 'Cabin_B50', 'Cabin_B51 B53 B55', 'Cabin_B57 B59 B63 B66', 'Cabin_B58 B60', 'Cabin_B69', 'Cabin_B71', 'Cabin_B73', 'Cabin_B77', 'Cabin_B78', 'Cabin_B79', 'Cabin_B80', 'Cabin_B82 B84', 'Cabin_B86', 'Cabin_B94', 'Cabin_B96 B98', 'Cabin_C101', 'Cabin_C103', 'Cabin_C104', 'Cabin_C106', 'Cabin_C110', 'Cabin_C111', 'Cabin_C118', 'Cabin_C123', 'Cabin_C124', 'Cabin_C125', 'Cabin_C126', 'Cabin_C128', 'Cabin_C148', 'Cabin_C2', 'Cabin_C22 C26', 'Cabin_C23 C25 C27', 'Cabin_C30', 'Cabin_C32', 'Cabin_C45', 'Cabin_C46', 'Cabin_C47', 'Cabin_C49', 'Cabin_C50', 'Cabin_C52', 'Cabin_C54', 'Cabin_C62 C64', 'Cabin_C65', 'Cabin_C68', 'Cabin_C7', 'Cabin_C70', 'Cabin_C78', 'Cabin_C82', 'Cabin_C83', 'Cabin_C85', 'Cabin_C86', 'Cabin_C87', 'Cabin_C90', 'Cabin_C91', 'Cabin_C92', 'Cabin_C93', 'Cabin_C95', 'Cabin_C99', 'Cabin_D', 'Cabin_D10 D12', 'Cabin_D11', 'Cabin_D15', 'Cabin_D17', 'Cabin_D19', 'Cabin_D20', 'Cabin_D21', 'Cabin_D26', 'Cabin_D28', 'Cabin_D30', 'Cabin_D33', 'Cabin_D35', 'Cabin_D36', 'Cabin_D37', 'Cabin_D45', 'Cabin_D46', 'Cabin_D47', 'Cabin_D48', 'Cabin_D49', 'Cabin_D50', 'Cabin_D56', 'Cabin_D6', 'Cabin_D7', 'Cabin_D9', 'Cabin_E10', 'Cabin_E101', 'Cabin_E12', 'Cabin_E121', 'Cabin_E17', 'Cabin_E24', 'Cabin_E25', 'Cabin_E31', 'Cabin_E33', 'Cabin_E34', 'Cabin_E36', 'Cabin_E38', 'Cabin_E40', 'Cabin_E44', 'Cabin_E46', 'Cabin_E49', 'Cabin_E50', 'Cabin_E58', 'Cabin_E63', 'Cabin_E67', 'Cabin_E68', 'Cabin_E77', 'Cabin_E8', 'Cabin_F E69', 'Cabin_F G63', 'Cabin_F G73', 'Cabin_F2', 'Cabin_F33', 'Cabin_F38', 'Cabin_F4', 'Cabin_G6', 'Cabin_T', 'Cabin_nan']\n",
            "2024-10-30 07:44:28 - INFO - Dataset after one-hot encoding:\n",
            " PassengerId  Survived  Pclass                                                Name  Age  SibSp  Parch           Ticket    Fare  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Embarked_nan  Cabin_A10  Cabin_A14  Cabin_A16  Cabin_A19  Cabin_A20  Cabin_A23  Cabin_A24  Cabin_A26  Cabin_A31  Cabin_A32  Cabin_A34  Cabin_A36  Cabin_A5  Cabin_A6  Cabin_A7  Cabin_B101  Cabin_B102  Cabin_B18  Cabin_B19  Cabin_B20  Cabin_B22  Cabin_B28  Cabin_B3  Cabin_B30  Cabin_B35  Cabin_B37  Cabin_B38  Cabin_B39  Cabin_B4  Cabin_B41  Cabin_B42  Cabin_B49  Cabin_B5  Cabin_B50  Cabin_B51 B53 B55  Cabin_B57 B59 B63 B66  Cabin_B58 B60  Cabin_B69  Cabin_B71  Cabin_B73  Cabin_B77  Cabin_B78  Cabin_B79  Cabin_B80  Cabin_B82 B84  Cabin_B86  Cabin_B94  Cabin_B96 B98  Cabin_C101  Cabin_C103  Cabin_C104  Cabin_C106  Cabin_C110  Cabin_C111  Cabin_C118  Cabin_C123  Cabin_C124  Cabin_C125  Cabin_C126  Cabin_C128  Cabin_C148  Cabin_C2  Cabin_C22 C26  Cabin_C23 C25 C27  Cabin_C30  Cabin_C32  Cabin_C45  Cabin_C46  Cabin_C47  Cabin_C49  Cabin_C50  Cabin_C52  Cabin_C54  Cabin_C62 C64  Cabin_C65  Cabin_C68  Cabin_C7  Cabin_C70  Cabin_C78  Cabin_C82  Cabin_C83  Cabin_C85  Cabin_C86  Cabin_C87  Cabin_C90  Cabin_C91  Cabin_C92  Cabin_C93  Cabin_C95  Cabin_C99  Cabin_D  Cabin_D10 D12  Cabin_D11  Cabin_D15  Cabin_D17  Cabin_D19  Cabin_D20  Cabin_D21  Cabin_D26  Cabin_D28  Cabin_D30  Cabin_D33  Cabin_D35  Cabin_D36  Cabin_D37  Cabin_D45  Cabin_D46  Cabin_D47  Cabin_D48  Cabin_D49  Cabin_D50  Cabin_D56  Cabin_D6  Cabin_D7  Cabin_D9  Cabin_E10  Cabin_E101  Cabin_E12  Cabin_E121  Cabin_E17  Cabin_E24  Cabin_E25  Cabin_E31  Cabin_E33  Cabin_E34  Cabin_E36  Cabin_E38  Cabin_E40  Cabin_E44  Cabin_E46  Cabin_E49  Cabin_E50  Cabin_E58  Cabin_E63  Cabin_E67  Cabin_E68  Cabin_E77  Cabin_E8  Cabin_F E69  Cabin_F G63  Cabin_F G73  Cabin_F2  Cabin_F33  Cabin_F38  Cabin_F4  Cabin_G6  Cabin_T  Cabin_nan\n",
            "           1         0       3                             Braund, Mr. Owen Harris 22.0      1      0        A/5 21171  7.2500           0         1           0           0           1             0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0           0           0          0          0          0          0          0         0          0          0          0          0          0         0          0          0          0         0          0                  0                      0              0          0          0          0          0          0          0          0              0          0          0              0           0           0           0           0           0           0           0           0           0           0           0           0           0         0              0                  0          0          0          0          0          0          0          0          0          0              0          0          0         0          0          0          0          0          0          0          0          0          0          0          0          0          0        0              0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0          0           0          0           0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0            0            0            0         0          0          0         0         0        0          1\n",
            "           2         1       1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) 38.0      1      0         PC 17599 71.2833           1         0           1           0           0             0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0           0           0          0          0          0          0          0         0          0          0          0          0          0         0          0          0          0         0          0                  0                      0              0          0          0          0          0          0          0          0              0          0          0              0           0           0           0           0           0           0           0           0           0           0           0           0           0         0              0                  0          0          0          0          0          0          0          0          0          0              0          0          0         0          0          0          0          0          1          0          0          0          0          0          0          0          0        0              0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0          0           0          0           0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0            0            0            0         0          0          0         0         0        0          0\n",
            "           3         1       3                              Heikkinen, Miss. Laina 26.0      0      0 STON/O2. 3101282  7.9250           1         0           0           0           1             0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0           0           0          0          0          0          0          0         0          0          0          0          0          0         0          0          0          0         0          0                  0                      0              0          0          0          0          0          0          0          0              0          0          0              0           0           0           0           0           0           0           0           0           0           0           0           0           0         0              0                  0          0          0          0          0          0          0          0          0          0              0          0          0         0          0          0          0          0          0          0          0          0          0          0          0          0          0        0              0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0          0           0          0           0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0            0            0            0         0          0          0         0         0        0          1\n",
            "           4         1       1        Futrelle, Mrs. Jacques Heath (Lily May Peel) 35.0      1      0           113803 53.1000           1         0           0           0           1             0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0           0           0          0          0          0          0          0         0          0          0          0          0          0         0          0          0          0         0          0                  0                      0              0          0          0          0          0          0          0          0              0          0          0              0           0           0           0           0           0           0           0           1           0           0           0           0           0         0              0                  0          0          0          0          0          0          0          0          0          0              0          0          0         0          0          0          0          0          0          0          0          0          0          0          0          0          0        0              0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0         0         0          0           0          0           0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0         0            0            0            0         0          0          0         0         0        0          0\n",
            "2024-10-30 07:44:52 - INFO - Scaling Numerical Features\n",
            "2024-10-30 07:44:52 - INFO - Summary statistics before scaling:\n",
            "2024-10-30 07:44:52 - INFO - \n",
            "              Age        Fare\n",
            "count  891.000000  891.000000\n",
            "mean    29.699118   32.204208\n",
            "std     13.002015   49.693429\n",
            "min      0.420000    0.000000\n",
            "25%     22.000000    7.910400\n",
            "50%     29.699118   14.454200\n",
            "75%     35.000000   31.000000\n",
            "max     80.000000  512.329200\n",
            "2024-10-30 07:44:52 - INFO - Numerical features scaled using StandardScaler.\n",
            "2024-10-30 07:44:52 - INFO - Summary statistics after scaling:\n",
            "2024-10-30 07:44:52 - INFO - \n",
            "                Age          Fare\n",
            "count  8.910000e+02  8.910000e+02\n",
            "mean   2.232906e-16  3.987333e-18\n",
            "std    1.000562e+00  1.000562e+00\n",
            "min   -2.253155e+00 -6.484217e-01\n",
            "25%   -5.924806e-01 -4.891482e-01\n",
            "50%    0.000000e+00 -3.573909e-01\n",
            "75%    4.079260e-01 -2.424635e-02\n",
            "max    3.870872e+00  9.667167e+00\n",
            "2024-10-30 07:45:23 - INFO - Handling Class Imbalance with SMOTE\n",
            "2024-10-30 07:45:23 - INFO - Original target class distribution:\n",
            "Survived\n",
            "0    549\n",
            "1    342\n",
            "2024-10-30 07:47:01 - INFO - Handling Class Imbalance with SMOTE\n",
            "2024-10-30 07:47:01 - INFO - Original target class distribution:\n",
            "Survived\n",
            "0    549\n",
            "1    342\n",
            "2024-10-30 07:49:07 - INFO - Handling Class Imbalance with SMOTE\n",
            "2024-10-30 07:49:07 - INFO - Original target class distribution:\n",
            "Survived\n",
            "0    549\n",
            "1    342\n",
            "2024-10-30 07:49:08 - INFO - Resampled target class distribution:\n",
            "Survived\n",
            "0    549\n",
            "1    549\n",
            "2024-10-30 07:50:05 - INFO - Hyperparameter Tuning and Cross-Validation\n",
            "2024-10-30 07:50:05 - INFO - Performed hyperparameter tuning using GridSearchCV.\n",
            "2024-10-30 07:50:05 - INFO - Best parameters found: {'max_depth': 3, 'n_estimators': 50}\n",
            "2024-10-30 07:50:05 - INFO - Best cross-validation score: 77.70%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d038aae5-a7aa-49f0-8e79-598c87122161\", \"data_pipeline_report.txt\", 14997)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DulntGxKb8wP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}